---
layout: post
category: RNN
---

This post covers **Seq2Seq** Encoder-Decoder Architecture. Seq2Seq architecture is heavily used in areas such as Machine Translation, Natural Language Processing, Chat Bots, etc.

## Table of contents

- [Related Issues](#related-issues)
- [Intuition](#intuition)
- [Building Encoders](#building-encoders)
- [Building Decoders](#building-decoders)

## [Related Issues](#related-issues)

- Issue of different length: In machine translation process, there is a problem of unmatching number of input vectors and desired output vectors.
- In other words, in most of the cases, sequences of one type of thing would not be in 1-to-1 relationship with sequences of another type of thing.

## [Intuition](#intuition)

![encoder-decoder-architecture](https://d2l.ai/_images/seq2seq.svg)
*Encoder-Decoder Architecture Figure*[^1]

- I first learn the representation of the English sentence.
- The entire representation is in the output of the blue RNN cells.
- Then pass that representation vector into decoder architecture - white cells.
- Decoder parts starts with encoder's input and the EOS signal.

> As you can recognize, that one output vector of encoder architecture is doing a lot of **heavy lifting**. That one vector is trying to represent the entirely of the English sentence. Currently, it's not a long sentence, but imagine that sentence length grows. This could be a challenging problem.

## [Building Encoders](#building-encoders)

### Materials we need

1. One-hot vectors of words
2. Word2Vec embedding layers
3. LSTM units
   - LSTM units can be *doubled* or *stacked*.
   - Doubled LSTM cells have their **own, separate sets** of weights and biases.
   - Stacked LSTM cells are additional layers. The output values from the unrolled LSTM units in the first layer(the short-term memories, or hidden states) are used as the inputs to the unrolled LSTM units in the second layer.
  
### Architecture of Encoders

![encoder-decoder-in-depth](https://docs.chainer.org/en/stable/_images/lstm-rnn.png)
*Encoder-Decoder Architecture Detailed Figure*[^2]

---
{: data-content="footnotes"}

[^1]: Figure from *[this article](https://d2l.ai/chapter_recurrent-modern/seq2seq.html)*
[^2]: Figure from *[this article](https://docs.chainer.org/en/stable/examples/seq2seq.html)*
